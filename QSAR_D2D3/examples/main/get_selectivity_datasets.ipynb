{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "filters package has been imported!\n"
     ]
    }
   ],
   "source": [
    "import os, sys\n",
    "from pathlib import Path\n",
    "home = str(Path.home())\n",
    "core_dir = home+'/repositories/ai-x/core'\n",
    "sys.path.insert(0, core_dir)\n",
    "selectivity_dir = core_dir + \"/selectivity\"\n",
    "sys.path.insert(0, selectivity_dir)\n",
    "\n",
    "from selectivity import *\n",
    "\n",
    "# command line arguments\n",
    "chembl_version = \"C33\"\n",
    "n = 200\n",
    "num_of_val = 10\n",
    "target = \"DR\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "target1, target2, assaydefinition1, assaydefinition2, \\\n",
    "        measurement1, measurement2, target1_source, target2_source = get_target_information(target)\n",
    "# source data\n",
    "path1 = target1_source\n",
    "path2 = target2_source\n",
    "dict_dataset = get_dataset_dict(target1, assaydefinition1, measurement1, target2, assaydefinition2, measurement2)\n",
    "ls_datasets = list(dict_dataset.values())\n",
    "\n",
    "# Prepare output directories\n",
    "datadir = f\"new_selectivity_datasets/{chembl_version}_{n}/\"\n",
    "check_output_dir(datadir, keep_old = False)\n",
    "for dataset in ls_datasets:\n",
    "    check_output_dir(datadir + dataset, keep_old = False)\n",
    "    \n",
    "target1 = get_df(path1)  # get df with columns containing chembl, pki, and smile string\n",
    "target2 = get_df(path2)  # get df with columns containing chembl, pki, and smile string\n",
    "target1 = check_similarity_within_df(target1)  # checks if there are any similar compounds within its own df\n",
    "target2 = check_similarity_within_df(target2)  # checks if there are any similar compounds within its own df\n",
    "target1['classification'] = [0 if x < 5.00 else 1 if 6.00 < x else 'nan' for x in target1['pKi']]\n",
    "target2['classification'] = [0 if x < 5.00 else 1 if 6.00 < x else 'nan' for x in target2['pKi']]\n",
    "mol_dup_pairs = get_mol_dup_pairs(target1, target2)  # a paired set, referring to similar indexes between d2 and d3\n",
    "df_overlap = get_overlap(target1, target2, mol_dup_pairs)  # combines protein1 and protein2 (horizontally), only returns similar compounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 validation index #\n",
      "(2) Protein 1 & 2 datasets created\n",
      "(2) Protein 1 & 2 Overlapping datasets created\n",
      "(2) Ratio of protein 1 & 2 - regression and classification datasets created\n",
      "1 validation index #\n",
      "(2) Protein 1 & 2 datasets created\n",
      "(2) Protein 1 & 2 Overlapping datasets created\n",
      "(2) Ratio of protein 1 & 2 - regression and classification datasets created\n",
      "2 validation index #\n",
      "(2) Protein 1 & 2 datasets created\n",
      "(2) Protein 1 & 2 Overlapping datasets created\n",
      "(2) Ratio of protein 1 & 2 - regression and classification datasets created\n",
      "3 validation index #\n",
      "(2) Protein 1 & 2 datasets created\n",
      "(2) Protein 1 & 2 Overlapping datasets created\n",
      "(2) Ratio of protein 1 & 2 - regression and classification datasets created\n",
      "4 validation index #\n",
      "(2) Protein 1 & 2 datasets created\n",
      "(2) Protein 1 & 2 Overlapping datasets created\n",
      "(2) Ratio of protein 1 & 2 - regression and classification datasets created\n",
      "5 validation index #\n",
      "(2) Protein 1 & 2 datasets created\n",
      "(2) Protein 1 & 2 Overlapping datasets created\n",
      "(2) Ratio of protein 1 & 2 - regression and classification datasets created\n",
      "6 validation index #\n",
      "(2) Protein 1 & 2 datasets created\n",
      "(2) Protein 1 & 2 Overlapping datasets created\n",
      "(2) Ratio of protein 1 & 2 - regression and classification datasets created\n",
      "7 validation index #\n",
      "(2) Protein 1 & 2 datasets created\n",
      "(2) Protein 1 & 2 Overlapping datasets created\n",
      "(2) Ratio of protein 1 & 2 - regression and classification datasets created\n",
      "8 validation index #\n",
      "(2) Protein 1 & 2 datasets created\n",
      "(2) Protein 1 & 2 Overlapping datasets created\n",
      "(2) Ratio of protein 1 & 2 - regression and classification datasets created\n",
      "9 validation index #\n",
      "(2) Protein 1 & 2 datasets created\n",
      "(2) Protein 1 & 2 Overlapping datasets created\n",
      "(2) Ratio of protein 1 & 2 - regression and classification datasets created\n"
     ]
    }
   ],
   "source": [
    "num_of_val = 10\n",
    "\n",
    "for i in range(num_of_val):\n",
    "    np.random.seed(i)\n",
    "    suffix = str(i)\n",
    "    print(suffix + \" validation index #\")\n",
    "\n",
    "    # dataset 1 and 2) split from original chembl dataset\n",
    "    ls_target1_indexes, ls_target2_indexes, ls_overlap_indexes = get_similar_indexes(mol_dup_pairs, n)  # get n number of similar indexes\n",
    "    target1_training, target1_validation = training_validation_datasplit(target1, ls_target1_indexes)  # split into training and validation\n",
    "    target2_training, target2_validation = training_validation_datasplit(target2, ls_target2_indexes)  # split into training and validation\n",
    "    # save datasets\n",
    "    save_one_dataset(f\"{datadir}/{ls_datasets[0]}/\", target1_training, target1_validation, suffix)  # first dataset\n",
    "    save_one_dataset(f\"{datadir}/{ls_datasets[1]}/\", target2_training, target2_validation, suffix)  # second dataset\n",
    "    print(f\"(2) Protein 1 & 2 datasets created\")\n",
    "\n",
    "    # dataset 3 and 4) two overlapping datasets.\n",
    "    # Find overlapping compounds between target 1 and target 2, concatenate them, then save them separately.\n",
    "    df_training, df_validation = training_validation_datasplit(df_overlap, ls_overlap_indexes)\n",
    "    df_train_overlap1, df_val_overlap1, df_train_overlap2, df_val_overlap2 = split_overlapped_df(df_training, df_validation)\n",
    "\n",
    "    # save datasets\n",
    "    save_one_dataset(f\"{datadir}/{ls_datasets[2]}/\", df_train_overlap1, df_val_overlap1, suffix)  # first dataset\n",
    "    save_one_dataset(f\"{datadir}/{ls_datasets[3]}/\", df_train_overlap2, df_val_overlap2, suffix)  # second dataset\n",
    "    print(f\"(2) Protein 1 & 2 Overlapping datasets created\")\n",
    "\n",
    "    # dataset 5) ratios - reg and class\n",
    "    save_ratios(f\"{datadir}/{ls_datasets[4]}/\", df_training, df_validation, suffix)\n",
    "    print(\"(2) Ratio of protein 1 & 2 - regression and classification datasets created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
